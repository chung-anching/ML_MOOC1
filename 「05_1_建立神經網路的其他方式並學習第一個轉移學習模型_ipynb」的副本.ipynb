{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "「05-1. 建立神經網路的其他方式並學習第一個轉移學習模型.ipynb」的副本",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:tf2py38]",
      "language": "python",
      "name": "conda-env-tf2py38-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb_VGxUWvFWt"
      },
      "source": [
        "# 主題 05-1. 用不同方式使用 Sequential 及學習建立第一個轉移學習模型\n",
        "\n",
        "【註】因 TensorFlow 2 已做了一些改變, 例如完全整合了 Keras。到 2021 年的今天, 有一些細節也做了調整。因此我們依新的規範修改了程式。最大的不同是, 以後大家直接安裝 tensorflow 即可, 不用再另外裝 keras。\n",
        "\n",
        "讓我們回顧一下生命中第一個做出來的神經網路..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l98iITAfvFW0"
      },
      "source": [
        "## 1. 初始準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwJo8g7gvFW1"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqmc0OOGvFW3"
      },
      "source": [
        "# tf.Keras functions\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# tf.Keras dataset\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# tf.Keras utilis function\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0JNye5LvFW6"
      },
      "source": [
        "## 2. 讀入 MNIST 數據庫"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH_hUdmEvFW7"
      },
      "source": [
        "### 2.1 由 Keras 讀入 MNIST\n",
        "Keras 很貼心的幫我們準備好 MNIST 數據庫, 我們可以這樣讀進來 (第一周課程中已經讀過)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHYkuVZevFW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "758c25f6-63d3-445f-d027-c77185a13cd6"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDl0QQ4HvFW_"
      },
      "source": [
        "資料的長相"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxJ0fma1vFXB",
        "outputId": "af3866e5-f788-407a-bcb4-0040d5f9bd52"
      },
      "source": [
        "print(\"總共有 %d 訓練資料，每筆資料的尺寸為 %d x %d\" %x_train.shape)\n",
        "print(\"總共有 %d 測試資料，每筆資料的尺寸為 %d x %d\" %x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "總共有 60000 訓練資料，每筆資料的尺寸為 28 x 28\n",
            "總共有 10000 測試資料，每筆資料的尺寸為 28 x 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lVctZQ2vFXG"
      },
      "source": [
        "### 2.3 輸入格式整理\n",
        "\n",
        "我們現在要用標準神經網路學學手寫辨識。原來的每筆數據是個 28x28 的矩陣 (array), 但標準神經網路只吃「平平的」, 也就是每次要 28x28=784 長的向量。因此我們要用 `reshape` 調校一下。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aZPiCJavFXH"
      },
      "source": [
        "x_train = x_train.reshape(60000, 784)/255 #一次把6萬筆資料做完\n",
        "x_test = x_test.reshape(10000, 784)/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7i1nZbEvFXI"
      },
      "source": [
        "為了後面需要，我們把訓練/測試資料中的數字 0, 1 資料，複製一份出來"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy7gI6sUvFXJ"
      },
      "source": [
        "x_train_01 = x_train[y_train <= 1]  #對list取條件: List[] = List[條件]\n",
        "x_test_01 = x_test[y_test <= 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05mvPAs_vFXL"
      },
      "source": [
        "並將 label 轉換成 one-hot encoding 的形式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6pp9z3zvFXM"
      },
      "source": [
        "y_train_10 = to_categorical(y_train, 10)\n",
        "y_test_10 = to_categorical(y_test, 10)\n",
        "\n",
        "y_train_01 = y_train[y_train <= 1]\n",
        "y_train_01 = to_categorical(y_train_01, 2)\n",
        "\n",
        "y_test_01 = y_test[y_test <= 1]\n",
        "y_test_01 = to_categorical(y_test_01, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7N1VsGzvFXN"
      },
      "source": [
        "養成良好的習慣，適時的確認資料的大小以確保資料的一致性(分布情況)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrbS0zwavFXO",
        "outputId": "97dad803-464c-407c-ba16-6aa1aa076543"
      },
      "source": [
        "x_train_01.shape, x_test_01.shape  #12665=約60000/5:平均分布"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12665, 784), (2115, 784))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0whzgllvFXO",
        "outputId": "14de71ef-2f03-42ef-d9b9-b8a57f56e303"
      },
      "source": [
        "y_train_01.shape, y_test_01.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12665, 2), (2115, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGh3tcE-vFXP"
      },
      "source": [
        "## 3. 回顧一下 Sequential API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCxJz6ALvFXP"
      },
      "source": [
        "在一開始的時候，我們以下列的方式建立了一個具有下列設定\n",
        "\n",
        "* 使用 <span style=\"color:red;\">2</span> 個 hidden layers\n",
        "* 每個 hidden layer 用 <span style=\"color:red;\">500</span> 個神經元\n",
        "* Activation Function 唯一指名 <span style=\"color:red;\">sigmoid</span>\n",
        "\n",
        "的神經網路，建立指令是透過建立 `Sequential()` 和 `.add` 的方式逐層建立，如下："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2srYeVMvFXQ",
        "outputId": "41cd6c11-f87c-4c5c-b595-3d6664ee61ad"
      },
      "source": [
        "# Construct a sandbox to put layers inside- 建立空的盒子\n",
        "model = Sequential()  \n",
        "\n",
        "# Put fully-connected layers (Dense) inside \n",
        "model.add(Dense(500, input_dim=784)) #:784*500+500=392500\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(500))         #:500*500+500=392500\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 500)               392500    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5010      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 648,010\n",
            "Trainable params: 648,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdzaUocBvFXR"
      },
      "source": [
        "### 3.1 觀察 model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk6mPMebvFXR"
      },
      "source": [
        "觀察 `model.layers`，可以發現 `model` 其實就是一堆神經網路層疊起來。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImnNI2muvFXS",
        "scrolled": true,
        "outputId": "669b3a8a-ca17-4a41-a47b-7623425a2807"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.core.Dense at 0x7f6bca0ee1d0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7f6bca0ee250>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f6c1137cb10>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7f6bc052dd50>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f6bc051a690>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7f6bc054e9d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skfcm6MlvFXT"
      },
      "source": [
        "換言之，剛剛每一個 `.add` 其實在做的事情就是：\n",
        "\n",
        "`model.add(Dense(500, input_dim=784))` 是將 `<keras.layers.core.Activation at 0xe558ef0>` 加進 model.layers\n",
        "\n",
        "`model.add(Activation('sigmoid'))` 是將 `<keras.layers.core.Dense at 0xe58a278>` 加入 model.layers\n",
        "\n",
        "`model.add(Dense(500))` 是將 `<keras.layers.core.Dense at 0xe58a278>` 加入 model.layers\n",
        "\n",
        "`model.add(Activation('sigmoid'))` 是將 `<keras.layers.core.Activation at 0xe558d68>` 加入 model.layers\n",
        "\n",
        "`model.add(Dense(10))` 是將 `<keras.layers.core.Activation at 0xe558d68>` 加入 model.layers\n",
        "\n",
        "`model.add(Activation('softmax'))` 是將 `<keras.layers.core.Activation at 0xe58a898>` 加入 model.layers\n",
        "\n",
        "* 這邊的 at 0xe558ef0 代表的是記憶體位置，每次執行都會不一樣，所以和上面結果不同是正常的。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujMb3P8jvFXT"
      },
      "source": [
        "### 3.2 以 list 的形式使用 Sequential API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_7VFtnovFXU"
      },
      "source": [
        "換言之，神經網路其實就是將隱藏層逐層堆疊在一起的 list，因此，我們也可以 list 的形式來建立相同的神經網路。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ9omKN-vFXU"
      },
      "source": [
        "首先，我們將兩個隱藏層及其 Activation Function 分別寫在 list 中，如下："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "powPJgeGvFXU"
      },
      "source": [
        "first_layer = [Dense(500, input_dim=784), \n",
        "               Activation('sigmoid')]\n",
        "\n",
        "second_layer = [Dense(500), \n",
        "                Activation('sigmoid')]\n",
        "\n",
        "output_layer = [Dense(10), \n",
        "                Activation('softmax')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNWZut5FvFXV"
      },
      "source": [
        "從基本的 Python 資料結構中，我們知道 list 可以用 `+` 來進行合併，所以我們先來看看這三個 list 合併後的樣子。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct4bsgzWvFXV",
        "outputId": "1cfac4d0-a8c0-4ad1-fca2-8c7b834d70fa"
      },
      "source": [
        "first_layer + second_layer + output_layer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.core.Dense at 0x7f6bca104fd0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7f6bc04eafd0>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f6bca104f10>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7f6bc04fa490>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f6bc04fa210>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7f6bc04fa9d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnihU77pvFXW"
      },
      "source": [
        "合併起來的 list 看起來就像是**某個** `model.layers` 一樣，我們接著要做的，就讓這個 list **真的**變成某個神經網路的 `.layers`\n",
        "\n",
        "很簡單，只要將寫成 list 的隱藏層 `+` 起來送進 `Sequential` 中即可。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TEk37SVvFXW"
      },
      "source": [
        "model = Sequential(first_layer + second_layer + output_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xysvk45PvFXW",
        "scrolled": true,
        "outputId": "dc3bcaa9-02c3-4090-dc71-873fb6010281"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 500)               392500    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                5010      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 648,010\n",
            "Trainable params: 648,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7pvxEPvvFXX"
      },
      "source": [
        "Q: 用 `.add` 和用 list 寫法建立的神經網路之差異？\n",
        "\n",
        "A: 沒有任何差別，前者可以很直覺的建立神經網路，但後者則為使用轉移學習(transfer Learning)的手法之一，前者雖也可做，但較麻煩。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxr6eLh4vFXX"
      },
      "source": [
        "## 4. 情境題:假設我們手上有一個好棒棒的 MNIST 手寫辨識模型，但我今天想建立可以辨識 0 或 1 的模型，除了最後一層，想沿用前兩層的網路設定及結構，我該怎麼做？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFPG2RcHvFXX"
      },
      "source": [
        "首先，我們準備一個上面一樣的神經網路手寫辨識模型，除了最後一層之外都被包在一起。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sT9p3h7vFXY",
        "outputId": "42256904-bfe5-4375-963f-9ce87797be75"
      },
      "source": [
        "all_except_last = [Dense(500, input_dim=784),  #要的前兩層定義在同一個list裡面\n",
        "          Activation('sigmoid'),\n",
        "          Dense(500), \n",
        "          Activation('sigmoid')]\n",
        "\n",
        "output_layer = [Dense(10),         #要改變的最後一層自己一個list\n",
        "         Activation('softmax')]\n",
        "\n",
        "model_0_to_9 = Sequential(all_except_last + output_layer)\n",
        "model_0_to_9.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 500)               392500    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                5010      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 648,010\n",
            "Trainable params: 648,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "SNEQUdL07-KM",
        "outputId": "678f3c8c-d179-4e1f-aa12-dbf35c32ce43"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    258\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTiEISr0vFXY"
      },
      "source": [
        "建立完成後，我們讀取第一周已經訓練好的神經網路權重。\n",
        "\n",
        "若同學們沒有 `handwriting_model_weights.h5` 這份模型的權重檔，請至 https://github.com/yenlung/Deep-Learning-MOOC 下載"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAC3GcuDC8TR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezhpd0s0DdxH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "Ci6-bRBnvFXZ",
        "outputId": "96657193-ebe3-4534-b1a5-c3dc1e2afb6e"
      },
      "source": [
        "model_0_to_9.load_weights('stupid_model_weights.h5') #讀取沒有錯誤: 當時對應的模型跟現在是一樣的"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b5f5e7f0ee2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_0_to_9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stupid_model_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#讀取沒有錯誤: 當時對應的模型跟現在是一樣的\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2317\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   2318\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2319\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2320\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n\u001b[0;32m--> 427\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'stupid_model_weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EllWfxdwvFXZ"
      },
      "source": [
        "由於我們沒有要真的使用這個手寫辨識模型，所以不需要 compile、fit、predict 或 evaluate。\n",
        "\n",
        "接著，我們定義新的 output layer。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS7NeGv2vFXa"
      },
      "source": [
        "new_output_layer = [Dense(2), \n",
        "           Activation('softmax')]\n",
        "\n",
        "model_0_to_1 = Sequential(all_except_last + new_output_layer)  #新建立的model\n",
        "model_0_to_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkJPVfJkvFXb"
      },
      "source": [
        "要注意的是，如果我們僅沿用而不訓練到前兩層，我們可以透過下面的方式將借過來的神經網路 **冷凍** 起來"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYcZpXG9vFXc"
      },
      "source": [
        "for layer in all_except_last:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hsBuWeLvFXc"
      },
      "source": [
        "**冷凍**後的神經網路的 summary 會有些變化，你有發現嗎? ：)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgNO0pKkvFXd"
      },
      "source": [
        "model_0_to_1.summary() #Trainable params:只剩1002；Non-trainable params: 643000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5gMA_ggvFXd"
      },
      "source": [
        "接著，我們來訓練這個(有一部分架構及權重跟別人借用的) 0 或 1 手寫辨識模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEgkFAOevFXe"
      },
      "source": [
        "model_0_to_1.compile(loss='mse', optimizer=SGD(lr=0.1), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2iNgcLMvFXe"
      },
      "source": [
        "## 5. 訓練你的第一個透過轉移學習學到的神經網路\n",
        "\n",
        "恭喜! 我們完成了第一個 transfer leraning 的神經網路。這裡我們還有兩件事要決定:\n",
        "\n",
        "* 一次要訓練幾筆資料 (`batch_size`), 我們就 100 筆調一次參數好了\n",
        "* 這 ~~6 萬筆資料~~ 12665 筆資料一共要訓練幾次 (`epochs`), 我們訓練個 5 次試試 (因為只剩 0 或 1的資料了，訓練太多容易 over-fitting)\n",
        "\n",
        "於是最精彩的就來了。你要有比第一周快上100倍的心理準備... (這是因為訓練資料只剩下 1/5，且**可訓練**權重數量從 64萬變成 1千)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAttHJlLvFXe"
      },
      "source": [
        "x_train_01.shape, y_train_01.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6yC2mLAvFXf",
        "scrolled": true
      },
      "source": [
        "model_0_to_1.fit(x_train_01, y_train_01, batch_size=100, epochs=5)   #一開始的準確率很高(因為有前兩層)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok9G_QYTvFXf"
      },
      "source": [
        "score = model_0_to_1.evaluate(x_test_01, y_test_01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzonqbXVvFXf"
      },
      "source": [
        "print('測試資料的 loss:', score[0])\n",
        "print('測試資料正確率:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UquN0BovFXg"
      },
      "source": [
        "## 6. 恭喜你完成了第一個透過轉移學習得到的神經網路模型！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRgG_Fd9vFXh"
      },
      "source": [
        "雖然這個模型看起來很隨便，但轉移學習的模型**差不多**都是這樣建立的，實際上， Keras 亦提供許多被證實有良好表現且訓練好 (pre-trained) 的模型，如:\n",
        "\n",
        "* Xception\n",
        "* VGG16\n",
        "* VGG19\n",
        "* ResNet50\n",
        "* InceptionV3\n",
        "* InceptionResNetV2\n",
        "* MobileNet\n",
        "* DenseNet\n",
        "* NASNet\n",
        "\n",
        "詳細的使用方式可參考 Keras Documentation: https://keras.io/applications/\n",
        "\n",
        "但使用這些模型進行轉移學習，**可能**需要其他更彈性的神經網路寫法，更多神經網路的建構技巧，待下次課程繼續。"
      ]
    }
  ]
}