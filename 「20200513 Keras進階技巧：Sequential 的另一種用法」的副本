{"cells":[{"cell_type":"markdown","metadata":{"id":"XUZA3OvtRzK-"},"source":["\n","\u003cp align=\"center\"\u003e\n","  \u003cimg src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/3649/media/cifar-10.png\"\n","  /\u003e\n","  \u003ccenter\u003eCifar 10 資料庫\u003c/center\u003e\n","  \u003ccenter\u003e圖片來源: https://www.kaggle.com/\u003c/center\u003e\n","\u003c/p\u003e"]},{"cell_type":"markdown","metadata":{"id":"zJMS8p3wfPXO"},"source":["## 1: 切換 TensorFlow 版本至 2.x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PXNUanZvcwwZ"},"outputs":[],"source":["%tensorflow_version 2.x"]},{"cell_type":"markdown","metadata":{"id":"lRHFdNYAfWKJ"},"source":["## 2: 載入套件及資料集"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tS5xFeQwe9Xu"},"outputs":[],"source":["# Import some useful packages\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Layers for FNN\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten\n","\n","# Layers for CNN\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\n","\n","from tensorflow.keras.optimizers import SGD, Adam\n","\n","# For data preprocessing\n","from tensorflow.keras import datasets\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"markdown","metadata":{"id":"e8zYubaPfy-S"},"source":["## 3: 資料前處理 (Data Preprocessing)"]},{"cell_type":"markdown","metadata":{"id":"YleM4DH4NoOA"},"source":["CIFAR 10 是包含 10 種類的彩色小圖資料集，每張圖的尺寸為 $32\\times32$\n","\n","10 個類別分別是：飛機、交通工具、鳥、貓、鹿、狗、青蛙、馬、船、卡車"]},{"cell_type":"markdown","metadata":{"id":"AOAGjiPogF0w"},"source":["讀取 CIFAR 10 資料集"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4c5EYPsuNThg"},"outputs":[],"source":["name_list = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":50},"id":"ITug7sp2TAr5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 4s 0us/step\n"]}],"source":["# Load CIFAR 10\n","(X_train, y_train0), (X_test, y_test0) = datasets.cifar10.load_data()\n","\n","# Normalize the range of featurs\n","X_train = X_train / X_train.max()\n","X_test = X_test / X_test.max()\n","\n","# One-hot encoding\n","y_train = to_categorical(y_train0, 10)\n","y_test = to_categorical(y_test0, 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":264},"id":"CnRkalOEMx8U"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["idx = np.random.randint(X_train.shape[0])\n","X_sample = X_train[idx]\n","y_sample = y_train0[idx].squeeze()\n","\n","plt.imshow(X_sample)\n","plt.title(name_list[y_sample])\n","plt.axis('off');"]},{"cell_type":"markdown","metadata":{"id":"swp6zTOST8gD"},"source":["## 4: 建立用於分類 CIFAR 10 的卷積神經網路\n","\n","在這個部分，我們將逐步帶領大家建立經典的 CNN 模型 LeNet-5 的變形。\n","\n","LeNet-5 分成兩個部分，分別為卷積層與全連接層，兩部份之間是透過扁平層 (Flatten) ，將卷積層最後輸出的 2 維向量壓扁成 1 維向量。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jGEAVln9TRwa"},"outputs":[],"source":["model = Sequential()\n","\n","# First convolutional block\n","model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu'))\n","model.add(MaxPool2D())\n","\n","# Second convolutional block\n","model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n","model.add(MaxPool2D())\n","\n","# Third convolutional block\n","model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n","model.add(GlobalAveragePooling2D())\n","\n","# Fully-connected layers as a classfier\n","model.add(Dense(units=256, activation='relu'))\n","\n","# Ouput layer: # of neurons = # of classes with softmax activation\n","model.add(Dense(units=10, activation='softmax'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":420},"id":"floU0of05vJj"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 16, 16, 128)       36992     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 8, 8, 512)         590336    \n","_________________________________________________________________\n","global_average_pooling2d (Gl (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               131328    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                2570      \n","=================================================================\n","Total params: 762,122\n","Trainable params: 762,122\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"GWdFSj9OcYWl"},"source":["### 編譯模型: 設定模型訓練時的設定\n","\n","- Optimizer: Stochastic Gradient Descent (SGD)\n","- Loss: categorical cross-entropy "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"86fvl2DHcKwj"},"outputs":[],"source":["model.compile(loss='categorical_crossentropy', \n","              optimizer=Adam(),\n","              metrics=['categorical_accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"-Zz5yHOzdUgv"},"source":["### 訓練模型: 透過訓練來學習分類資料的函數"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":134},"id":"LVdaaVOJcKrk"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","391/391 [==============================] - 37s 13ms/step - loss: 1.7791 - categorical_accuracy: 0.3232 - val_loss: 1.5215 - val_categorical_accuracy: 0.4350\n","Epoch 2/3\n","391/391 [==============================] - 5s 12ms/step - loss: 1.4487 - categorical_accuracy: 0.4676 - val_loss: 1.3433 - val_categorical_accuracy: 0.5097\n","Epoch 3/3\n","391/391 [==============================] - 5s 12ms/step - loss: 1.2804 - categorical_accuracy: 0.5320 - val_loss: 1.2089 - val_categorical_accuracy: 0.5555\n"]},{"data":{"text/plain":["\u003ctensorflow.python.keras.callbacks.History at 0x7fa682fdc850\u003e"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(X_train, y_train, \n","          batch_size=128, \n","          epochs=3,\n","          validation_data=(X_test, y_test)\n","          )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dnuqnY1TLpgR"},"outputs":[],"source":["model.save_weights('LeNet5_CIFAR10.h5')"]},{"cell_type":"markdown","metadata":{"id":"5IJhvV_BSo9x"},"source":["### 模型預測: 預測資料集的準確率"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":84},"id":"btoBDRueSokB"},"outputs":[{"name":"stdout","output_type":"stream","text":["1563/1563 [==============================] - 5s 3ms/step - loss: 1.1987 - categorical_accuracy: 0.5627\n","313/313 [==============================] - 1s 3ms/step - loss: 1.2089 - categorical_accuracy: 0.5555\n","Train Accuracy: 56.26800060272217\n","Test Accuracy: 55.549997091293335\n"]}],"source":["# model.load_weights('LeNet5_CIFAR10.h5')\n","\n","score_train = model.evaluate(X_train, y_train)\n","score_test = model.evaluate(X_test, y_test)\n","\n","print(f'Train Accuracy: {score_train[1]*100}')\n","print(f'Test Accuracy: {score_test[1]*100}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mV_jjr02p6Uz"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":151},"id":"P4PKj-iYp3EB"},"outputs":[{"data":{"text/plain":["[\u003ctensorflow.python.keras.layers.convolutional.Conv2D at 0x7fa63c9632d0\u003e,\n"," \u003ctensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fa63c963290\u003e,\n"," \u003ctensorflow.python.keras.layers.convolutional.Conv2D at 0x7fa63ca13a50\u003e,\n"," \u003ctensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fa6434a5f10\u003e,\n"," \u003ctensorflow.python.keras.layers.convolutional.Conv2D at 0x7fa64349d350\u003e,\n"," \u003ctensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x7fa646c91910\u003e,\n"," \u003ctensorflow.python.keras.layers.core.Dense at 0x7fa64349d210\u003e,\n"," \u003ctensorflow.python.keras.layers.core.Dense at 0x7fa63c87c790\u003e]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["model.layers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"UyxQIxGNp6-A"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"0G7lUOLHQEjr"},"source":["## 5: 另一種使用 Sequential 建立模型的方式"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"14YYzYYwcKpE"},"outputs":[],"source":["CNN_layers = [Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', name='Conv_1'),\n","              MaxPool2D(),\n","              Conv2D(128, (3, 3), padding='same', activation='relu', name='Conv_2'),\n","              MaxPool2D(),\n","              Conv2D(512, (3, 3), padding='same', activation='relu', name='Conv_3'),\n","              GlobalAveragePooling2D()]\n","\n","FC_layers = [Dense(units=256, activation='relu'),\n","             Dense(units=10, activation='softmax')]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":151},"id":"xn7EzCCgqkDs"},"outputs":[{"data":{"text/plain":["[\u003ctensorflow.python.keras.layers.convolutional.Conv2D at 0x7fa630318e10\u003e,\n"," \u003ctensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fa630310b50\u003e,\n"," \u003ctensorflow.python.keras.layers.convolutional.Conv2D at 0x7fa630320950\u003e,\n"," \u003ctensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fa630320c10\u003e,\n"," \u003ctensorflow.python.keras.layers.convolutional.Conv2D at 0x7fa630310e50\u003e,\n"," \u003ctensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x7fa630325250\u003e,\n"," \u003ctensorflow.python.keras.layers.core.Dense at 0x7fa630318790\u003e,\n"," \u003ctensorflow.python.keras.layers.core.Dense at 0x7fa630325710\u003e]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["CNN_layers + FC_layers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":420},"id":"hvmVUw4krEJq"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 16, 16, 128)       36992     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 8, 8, 512)         590336    \n","_________________________________________________________________\n","global_average_pooling2d (Gl (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               131328    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                2570      \n","=================================================================\n","Total params: 762,122\n","Trainable params: 762,122\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":420},"id":"43XOpYqROKzD"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                2570      \n","=================================================================\n","Total params: 762,122\n","Trainable params: 762,122\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model_2 = Sequential(CNN_layers+FC_layers)\n","model_2.summary()"]},{"cell_type":"markdown","metadata":{"id":"Axv5GfyzRfMZ"},"source":["####  與使用 `model.add` 建立模型的差異？"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_tmJIForZPlR"},"outputs":[],"source":["model_2.compile(loss='categorical_crossentropy', \n","                optimizer=Adam(),\n","                metrics=['categorical_accuracy'])\n","\n","model_2.load_weights('LeNet5_CIFAR10.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":84},"id":"Tb2cXnaV8FHy"},"outputs":[{"name":"stdout","output_type":"stream","text":["49/49 [==============================] - 3s 39ms/step - loss: 1.1987 - categorical_accuracy: 0.5627\n","10/10 [==============================] - 1s 112ms/step - loss: 1.2089 - categorical_accuracy: 0.5555\n","Train Accuracy: 56.26800060272217\n","Test Accuracy: 55.549997091293335\n"]}],"source":["score_train = model_2.evaluate(X_train, y_train, batch_size=1024)\n","score_test = model_2.evaluate(X_test, y_test, batch_size=1024)\n","\n","print(f'Train Accuracy: {score_train[1]*100}')\n","print(f'Test Accuracy: {score_test[1]*100}')"]},{"cell_type":"markdown","metadata":{"id":"W5Vf7bbrQIQc"},"source":["## 6: 遷移學習 (Transfer Learning) 中的 Layer Transfer 的技巧"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":50},"id":"OmOkvmGXLjMo"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n","169009152/169001437 [==============================] - 4s 0us/step\n"]}],"source":["# Load CIFAR 100\n","(U_train, v_train0), (U_test, v_test0) = datasets.cifar100.load_data()\n","\n","# Normalize the range of featurs\n","U_train = U_train / U_train.max()\n","U_test = U_test / U_test.max()\n","\n","# One-hot encoding\n","v_train = to_categorical(v_train0, 100)\n","v_test = to_categorical(v_test0, 100)"]},{"cell_type":"markdown","metadata":{"id":"iRjjVxyiYxi4"},"source":["LeNet-5 for CIFAR-10 (model_2)\n","```\n","CNN_layers = [Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', name='Conv_1'),\n","              MaxPool2D(),\n","              Conv2D(128, (3, 3), padding='same', activation='relu', name='Conv_2'),\n","              MaxPool2D(),\n","              Conv2D(512, (3, 3), padding='same', activation='relu', name='Conv_3'),\n","              GlobalAveragePooling2D()]\n","\n","FC_layers = [Dense(units=256, activation='relu'),\n","             Dense(units=10, activation='softmax')]\n","```\n","\n","LeNet-5 for CIFAR-100\n","```\n","# From LeNet-5 for CIFAR-10\n","CNN_layers\n","\n","# New FC layers for CIFAR-100\n","FC_layers_CF100 = [Dense(units=256, activation='relu'),\n","                   Dense(units=128, activation='relu'),\n","                   Dense(units=100, activation='softmax')]\n","```\n","CNN_layers 是跟人家**借**來的。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qd-lSV5rSJYX"},"outputs":[],"source":["FC_layers_CF100 = [Dense(units=256, activation='relu'),\n","                   Dense(units=128, activation='relu'),\n","                   Dense(units=100, activation='softmax')]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":454},"id":"oF_YvZpEZuGD"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 512)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 100)               12900     \n","=================================================================\n","Total params: 805,348\n","Trainable params: 805,348\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model_CF100 = Sequential(CNN_layers+FC_layers_CF100)\n","model_CF100.summary()"]},{"cell_type":"markdown","metadata":{"id":"N2_KcAk4Z2Pv"},"source":["對照一下和 LeNet-5 for CIFAR-10 的差別"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":420},"id":"4E_nXlKyZ14h"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                2570      \n","=================================================================\n","Total params: 762,122\n","Trainable params: 762,122\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model_2.summary()"]},{"cell_type":"markdown","metadata":{"id":"X2tE6ef-a65s"},"source":["### 遷移學習的訓練方式\n","* Fine-tune: 新資料集的樣本數夠多，整個模型重新訓練\n","* Frozen: 當新資料集的樣本數不夠多，凍結借來的部分，只針對新建立的神經網路層訓練"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-Q1B1e96Z7p8"},"outputs":[],"source":["for layer in CNN_layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":454},"id":"szhsRPIXbb0F"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 512)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 100)               12900     \n","=================================================================\n","Total params: 805,348\n","Trainable params: 177,124\n","Non-trainable params: 628,224\n","_________________________________________________________________\n"]}],"source":["model_CF100.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Bu6OYc8PbfHA"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","391/391 [==============================] - 3s 7ms/step - loss: 3.8036 - categorical_accuracy: 0.1148 - val_loss: 3.4798 - val_categorical_accuracy: 0.1614\n","Epoch 2/5\n","391/391 [==============================] - 2s 6ms/step - loss: 3.3587 - categorical_accuracy: 0.1860 - val_loss: 3.2848 - val_categorical_accuracy: 0.1991\n","Epoch 3/5\n","391/391 [==============================] - 2s 6ms/step - loss: 3.1996 - categorical_accuracy: 0.2157 - val_loss: 3.1663 - val_categorical_accuracy: 0.2182\n","Epoch 4/5\n","391/391 [==============================] - 2s 6ms/step - loss: 3.0922 - categorical_accuracy: 0.2348 - val_loss: 3.0680 - val_categorical_accuracy: 0.2366\n","Epoch 5/5\n","391/391 [==============================] - 2s 6ms/step - loss: 3.0181 - categorical_accuracy: 0.2487 - val_loss: 3.0092 - val_categorical_accuracy: 0.2496\n"]},{"data":{"text/plain":["\u003ctensorflow.python.keras.callbacks.History at 0x7fa6301c2c10\u003e"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["model_CF100.compile(loss='categorical_crossentropy', \n","                    optimizer=Adam(),\n","                    metrics=['categorical_accuracy'])\n","\n","model_CF100.fit(U_train, v_train,\n","                batch_size=128, \n","                epochs=5,\n","                validation_data=(U_test, v_test)\n","                )"]},{"cell_type":"markdown","metadata":{"id":"MlZsfofSb5k1"},"source":["### 借來的神經網路 (的權重) 會如何變化？Frozen 的場合"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":84},"id":"7dOhdwRrdAwt"},"outputs":[{"name":"stdout","output_type":"stream","text":["1563/1563 [==============================] - 5s 3ms/step - loss: 1.1987 - categorical_accuracy: 0.5627\n","313/313 [==============================] - 1s 3ms/step - loss: 1.2089 - categorical_accuracy: 0.5555\n","Train Accuracy: 56.26800060272217\n","Test Accuracy: 55.549997091293335\n"]}],"source":["score_train = model_2.evaluate(X_train, y_train)\n","score_test = model_2.evaluate(X_test, y_test)\n","\n","print(f'Train Accuracy: {score_train[1]*100}')\n","print(f'Test Accuracy: {score_test[1]*100}')"]},{"cell_type":"markdown","metadata":{"id":"ysYktss3dE4J"},"source":["### 借來的神經網路 (的權重) 會如何變化？Fine-tune 的場合"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":50},"id":"vjCaXC6bb_n4"},"outputs":[{"name":"stdout","output_type":"stream","text":["391/391 [==============================] - 2s 6ms/step - loss: 2.9549 - categorical_accuracy: 0.2626 - val_loss: 2.9574 - val_categorical_accuracy: 0.2582\n"]},{"data":{"text/plain":["\u003ctensorflow.python.keras.callbacks.History at 0x7fa630066890\u003e"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["for layer in CNN_layers:\n","    layer.trainable = True   #這邊不像剛剛是false\n","\n","model_CF100.fit(U_train, v_train,\n","                batch_size=128, \n","                epochs=1,\n","                validation_data=(U_test, v_test)\n","                )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-Tt8jWVgvqKm"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 512)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 100)               12900     \n","=================================================================\n","Total params: 805,348\n","Trainable params: 805,348\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model_CF100.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":84},"id":"8jYVEtgJvBIe"},"outputs":[{"name":"stdout","output_type":"stream","text":["1563/1563 [==============================] - 5s 3ms/step - loss: 1.1987 - categorical_accuracy: 0.5627\n","313/313 [==============================] - 1s 3ms/step - loss: 1.2089 - categorical_accuracy: 0.5555\n","Train Accuracy: 56.26800060272217\n","Test Accuracy: 55.549997091293335\n"]}],"source":["score_train = model_2.evaluate(X_train, y_train)\n","score_test = model_2.evaluate(X_test, y_test)\n","\n","print(f'Train Accuracy: {score_train[1]*100}')\n","print(f'Test Accuracy: {score_test[1]*100}')"]},{"cell_type":"markdown","metadata":{"id":"7G2pTHXGfnzl"},"source":["使用 Layer Transfer 的注意事項\n","1. 若目的不同 (如；分類總數不同)，則須重新定義不同的全連接層\n","2. 若資料的輸入尺寸不同 (如：channel 數不同)，則也需針對輸入的部分調整"]},{"cell_type":"markdown","metadata":{"id":"6-CXv-J_lhB-"},"source":["雖然這個模型看起來很隨便，但轉移學習的模型**差不多**都是這樣建立的，實際上， Keras 亦提供許多被證實有良好表現且訓練好 (pre-trained) 的模型，如:\n","\n","* Xception\n","* VGG16\n","* VGG19\n","* ResNet50\n","* InceptionV3\n","* InceptionResNetV2\n","* MobileNet\n","* DenseNet\n","* NASNet\n","\n","詳細的使用方式可參考 Keras Documentation: https://keras.io/applications/\n","\n","但使用這些模型進行轉移學習，**可能**需要 ``Sequential`` 以外寫法，以及更多神經網路的建構技巧。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XVErcleXjv3R"},"outputs":[],"source":["from tensorflow.keras.applications.resnet50 import ResNet50"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"N42q2ROQliX8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n","102973440/102967424 [==============================] - 1s 0us/step\n"]}],"source":["model = ResNet50(weights='imagenet')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tcxVPVZ5j0Fk"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"OSew6gi3goiy"},"source":["## [NOT FINISHED] 遷移學習的實作，以 Class Activation Map (CAM) 為例"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9FViBYlTgfBG"},"outputs":[],"source":["FC_layers_new = [Dense(units=10, activation='softmax')]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":386},"id":"YzGxm7Qyg3nY","outputId":"8deb2388-55c5-4f32-c46b-24aea0fc1fe0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n","_________________________________________________________________\n","global_average_pooling2d_2 ( (None, 512)               0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 633,354\n","Trainable params: 633,354\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["classifier = Sequential(CNN_layers+FC_layers_new)\n","classifier.compile(loss='categorical_crossentropy', \n","                   optimizer=Adam(),\n","                   metrics=['categorical_accuracy'])\n","classifier.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fVvocZANhKsv"},"outputs":[{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-34-08605df8750b\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 4\u001b[0;31m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m           )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1105\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2691\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 2693\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2694\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n","\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."]}],"source":["model.fit(X_train, y_train, \n","          batch_size=128, \n","          epochs=20,\n","          validation_data=(X_test, y_test)\n","          )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":353},"id":"pN6CEmmehLgh"},"outputs":[],"source":["CAM_model = Sequential(CNN_layers[:-1]+FC_layers_new)\n","CAM_model.compile(loss='categorical_crossentropy', \n","                  optimizer=Adam(),\n","                  metrics=['categorical_accuracy'])\n","CAM_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":219},"id":"xzMhzBmihx0L"},"outputs":[],"source":["from PIL import Image\n","CAM = CAM_model.predict(X_train[idx:idx+1])[0, : ,: , y_sample]\n","CAM.resize(X_sample.shape)\n","\n","plt.subplot(1, 2, 1)\n","plt.imshow(X_sample)\n","\n","plt.subplot(1, 2, 2)\n","plt.imshow(np.clip(CAM, 0.1, 1), 'gray_r')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":286},"id":"DM2fZGEAkSLe"},"outputs":[],"source":["np.clip(CAM, 0.1, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2GyElQZBifTS"},"outputs":[],"source":["class_intensity = FC_layers_new[0].get_weights()[0][:, y_sample]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"pvt5gYO-jIPO","outputId":"f5dad685-2978-41b7-bfa4-8e3341a75e60"},"outputs":[{"data":{"text/plain":["(1, 8, 8, 10)"]},"execution_count":88,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["CAM_model.predict(X_train[idx:idx+1]).shape"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["OSew6gi3goiy"],"machine_shape":"hm","name":"「20200513 Keras進階技巧：Sequential 的另一種用法」的副本","provenance":[{"file_id":"https://github.com/yenlung/Deep-Learning-Basics/blob/master/04%20tfKeras%E9%80%B2%E9%9A%8E%E6%8A%80%E5%B7%A71_Sequential%20%E7%9A%84%E5%8F%A6%E4%B8%80%E7%A8%AE%E7%94%A8%E6%B3%95.ipynb","timestamp":1626132150086}],"version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":0}