{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "「colab03b使用紅樓夢生成器.ipynb」的副本",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyh-PyRXQc44"
      },
      "source": [
        "### 1. 讀入使用套件\n",
        "\n",
        "第一輪是讀進我們基本套件, 第二輪是 TensorFlow 用到的套件。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MspAqe3DUKcr"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuS7XODDUOrp"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import load_model, model_from_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "708oJY4vURVw"
      },
      "source": [
        "### 2. 讀入訓練好的 RNN 紅樓夢生成器\n",
        "\n",
        "這裡是參考[《精通機器學習-使用 Scikit-Learn, Keras 與 TensorFlow》](https://www.books.com.tw/products/0010854043?sloc=main)這本書中莎士比亞生成器的部份寫成的。架構很簡單,就每輸入 100 個字, 預測下一個字是什麼。雙層 LSTM, 每層 128 個神經元。訓練 10 次, 在 1080Ti GPU 的電腦上大概花了 10 個小時。\n",
        "\n",
        "以下會從我的 GitHub 重新讀入模型, 已下載模型請直接跳到下一段。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpWb7lhBU0Rq"
      },
      "source": [
        "from urllib.request import urlretrieve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCMoN9ZQVBPD",
        "outputId": "d735ef26-b9f4-4137-8928-cf28c17921ce"
      },
      "source": [
        "urlretrieve(\"https://raw.githubusercontent.com/yenlung/Deep-Learning-Basics/master/dream_rnn_architecture.json\", \"architecture.json\")\n",
        "urlretrieve(\"https://github.com/yenlung/Deep-Learning-Basics/raw/master/dream_rnn_weights.h5\", \"weights.h5\")\n",
        "urlretrieve(\"https://github.com/yenlung/Deep-Learning-Basics/raw/master/dream_tokenizer2.pkl\", \"tokenizer.pkl\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tokenizer.pkl', <http.client.HTTPMessage at 0x7f09216c9990>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AghtUi3V8xB"
      },
      "source": [
        "f = open('architecture.json', 'r')\n",
        "loaded_model = f.read()\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-GTCtDzWQdB",
        "outputId": "204bdb1e-bcb0-463c-97bd-e7fa86c9f83b"
      },
      "source": [
        "model = model_from_json(loaded_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-ucoaMEWhf5"
      },
      "source": [
        "model.load_weights(\"weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgCD002QWsUb"
      },
      "source": [
        "f = open('tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uMS1542VbWw"
      },
      "source": [
        "#### 【已下載紅樓夢生成器請執行這段】\n",
        "\n",
        "如果你已經在[我的 GitHub](https://github.com/yenlung/Deep-Learning-Basics) 中下載紅樓夢生成模型, 這包括:\n",
        "\n",
        "1. `dream_rnn` 資料夾, 這是模型和訓練好的權重。\n",
        "2. `dream_tokenizer2.pkl` 檔案, 這是模型使用的 tokenizer。\n",
        "\n",
        "存到你的 Google Drive, 放 Colab 程式的地方 (預設是 `Colab Notebooks` 資料夾)。那執行下面這一段, 不用再讀入一次模型資料。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVTnboB5cV6J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f6be555-7405-4d83-a97e-79f0b8123d21"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3SHSNpedT1D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1386346-9e51-4017-dc59-7e8de0258058"
      },
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJDe7oqFWeBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ccbb31-70a6-413f-916f-4dc8372f2b49"
      },
      "source": [
        "model = load_model('dream_rnn')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxeqaCs4Y7G9"
      },
      "source": [
        "f = open('dream_tokenizer2.pkl', 'rb')\n",
        "tokenizer = pickle.load(f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV5LKUzwY_Yw"
      },
      "source": [
        "### 4. 製造紅樓夢生成器\n",
        "\n",
        "首先 `max_id` 是記錄《紅樓夢》用到的所有不同的中文字字數, 包括新式標點符號。很讓人驚訝 (?) 的是, 字數並沒有想像中多。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U2xs9ZOgoB-"
      },
      "source": [
        "max_id = len(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDMLOoVqJ0k5"
      },
      "source": [
        "接下來是一段文字, 我們用事先訓練好的 tokenizer 換成一段數字, 最後用 one-hot encoding 回傳。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5b60vWjgo9t"
      },
      "source": [
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences([texts]))-1\n",
        "    return tf.one_hot(X, max_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qwEE6kEKJBW"
      },
      "source": [
        "這段程式主要依輸入的一段文字, 用我們的 model 去預測下一個字。注意像平常的分類問題, 這裡輸出是每人個字出現機率最高的。但都照這樣, 我們輸入同一段文字, 之後出現的文字永遠是一樣的! 常用的手法是去設定 `temperature`, `temperature` 接近 0, 大致上就取機率最高的字; `temperature` 越大就越隨機。太隨機就變成亂數取字! 一般 `temperature`設 1 左右效果最佳。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ddA1r_Ggtoh"
      },
      "source": [
        "def next_char(texts, temperature=1):\n",
        "    X_new = preprocess(texts)\n",
        "    y_predict = model.predict(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_predict) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBuIiQ59Liwk"
      },
      "source": [
        "最後就一段文字進來，再產生 `n_chars` 這麼多個字。我們原本一段文字只能生一個字, 那就一次生一個字, 最後要生多少個字就生多少個字。\n",
        "\n",
        "原本訓練我們一段是 100 個字去訓練的, 這裡超過 100 字時我們就取最後 100 個字丟入模型。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCOZ4EtlgwFc"
      },
      "source": [
        "def complete_text(texts, n_chars=50, temperature=1):\n",
        "    n_chars=int(n_chars)\n",
        "    for _ in range(n_chars):\n",
        "        texts = texts + next_char(texts[-100:], temperature)\n",
        "    return texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d73SL-UKgyPr"
      },
      "source": [
        "做成 web app 前, 先來測試一下。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "IQRXr6KQg36C",
        "outputId": "ee995527-a703-43c2-e448-9f549516ae7a"
      },
      "source": [
        "complete_text(\"自孫悟空從石頭中蹦出來之後，\", n_chars=300, temperature=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'自孫悟空從石頭中蹦出來之後，說道：「寶玉既有此事，不知何俗緣？」士隱道：「神仙長得如此。」雨村聽了，益發驚異：「請問仙長，何必如此？」士隱道：「寶玉，何嘗肯唸書，你這條心，原是如此的情緣完結，也不知道了。」雨村聽了，益發驚異：「你們這麼一個人，不知何俗而不！」雨村聽了，益發驚異：「請問仙長，何必如此？」士隱道：「此事不知。」雨村聽了，益發驚異：「請問仙長，何必如此？」士隱道：「此事不知。」雨村聽了，益發驚異：「請問仙長，何必如此？」士隱道：「神仙長佛。」雨村聽了，益發驚異：「請問仙長，何必如此？」士隱道：「神仙長名久，無佛有所。」雨村聽了，益發驚異：「你們不知道士隱，雨村再不知道。」雨村聽了，益發驚異：「請問仙長，何必如'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpUaHxdug6sI"
      },
      "source": [
        "### 5. 用 `gradio` 做成一個網路 app\n",
        "\n",
        "我們準備用 [`gradio`](https://gradio.app/) 套件, 神速做完一個 web app。最酷的是, 最後出現 `https://xxxx.gradio.app` 那個網址, 在你的 Colab 還在執行的時候, 任何人都可以用任何瀏覽器連進來使用!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd5zdVNHhPla",
        "outputId": "dd5f0d7f-ff5e-4881-9101-580dc10c3a1e"
      },
      "source": [
        "!pip install gradio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/7d/61f0caccef9b25659b202f469e197e935b23c585583798bc555167387621/gradio-2.1.4-py3-none-any.whl (71kB)\n",
            "\r\u001b[K     |████▋                           | 10kB 19.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 20kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 30kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 40kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 61kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.3MB/s \n",
            "\u001b[?25hCollecting Flask-Cors>=3.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/db/84/901e700de86604b1c4ef4b57110d4e947c218b9997adf5d38fa7da493bce/Flask_Cors-3.0.10-py2.py3-none-any.whl\n",
            "Collecting pycryptodome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/16/9627ab0493894a11c68e46000dbcc82f578c8ff06bc2980dcd016aea9bd3/pycryptodome-3.10.1-cp35-abi3-manylinux2010_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 35.5MB/s \n",
            "\u001b[?25hCollecting markdown2\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/be/3924cc1c0e12030b5225de2b4521f1dc729730773861475de26be64a0d2b/markdown2-2.4.0-py2.py3-none-any.whl\n",
            "Collecting Flask-Login\n",
            "  Downloading https://files.pythonhosted.org/packages/2b/83/ac5bf3279f969704fc1e63f050c50e10985e50fd340e6069ec7e09df5442/Flask_Login-0.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Requirement already satisfied: Flask>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from gradio) (1.1.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.1.5)\n",
            "Collecting analytics-python\n",
            "  Downloading https://files.pythonhosted.org/packages/30/81/2f447982f8d5dec5b56c10ca9ac53e5de2b2e9e2bdf7e091a05731f21379/analytics_python-1.3.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.19.5)\n",
            "Collecting flask-cachebuster\n",
            "  Downloading https://files.pythonhosted.org/packages/74/47/f3e1fedfaad965c81c2f17234636d72f71450f1b4522ca26d2b7eb4a0a74/Flask-CacheBuster-1.0.0.tar.gz\n",
            "Collecting ffmpy\n",
            "  Downloading https://files.pythonhosted.org/packages/bf/e2/947df4b3d666bfdd2b0c6355d215c45d2d40f929451cb29a8a2995b29788/ffmpy-0.3.0.tar.gz\n",
            "Collecting paramiko\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/19/124e9287b43e6ff3ebb9cdea3e5e8e88475a873c05ccdf8b7e20d2c4201e/paramiko-2.7.2-py2.py3-none-any.whl (206kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 51.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.23.0)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from Flask-Cors>=3.0.8->gradio) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (2.4.7)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2018.9)\n",
            "Collecting backoff==1.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/32/c5dd4f4b0746e9ec05ace2a5045c1fc375ae67ee94355344ad6c7005fd87/backoff-1.10.0-py2.py3-none-any.whl\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading https://files.pythonhosted.org/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl\n",
            "Collecting cryptography>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 47.0MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/57/2f5e6226a674b2bcb6db531e8b383079b678df5b10cdaa610d6cf20d77ba/PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 50.9MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/70/6d218afbe4c73538053c1016dd631e8f25fffc10cd01f5c272d7acf3c03d/bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.1->gradio) (2.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.5->paramiko->gradio) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio) (2.20)\n",
            "Building wheels for collected packages: flask-cachebuster, ffmpy\n",
            "  Building wheel for flask-cachebuster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flask-cachebuster: filename=Flask_CacheBuster-1.0.0-cp37-none-any.whl size=3372 sha256=f461cda770763f9a22d858136f2f8668864552af66767ad7f1c63c401d626f16\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/fc/a7/ab5712c3ace9a8f97276465cc2937316ab8063c1fea488ea77\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-cp37-none-any.whl size=4710 sha256=f898d0bb99821a1d92f3d3d3a261c0b937b3c4a4ea2d6201bcf348d05c70084f\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/ac/c4/bef572cb7e52bfca170046f567e64858632daf77e0f34e5a74\n",
            "Successfully built flask-cachebuster ffmpy\n",
            "Installing collected packages: Flask-Cors, pycryptodome, markdown2, Flask-Login, backoff, monotonic, analytics-python, flask-cachebuster, ffmpy, cryptography, pynacl, bcrypt, paramiko, gradio\n",
            "Successfully installed Flask-Cors-3.0.10 Flask-Login-0.5.0 analytics-python-1.3.1 backoff-1.10.0 bcrypt-3.2.0 cryptography-3.4.7 ffmpy-0.3.0 flask-cachebuster-1.0.0 gradio-2.1.4 markdown2-2.4.0 monotonic-1.6 paramiko-2.7.2 pycryptodome-3.10.1 pynacl-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNiAIAyehTXi"
      },
      "source": [
        "import gradio as gr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "bUGllKxphWgQ",
        "outputId": "21e536e6-a263-4685-a65c-beeaf45e9105"
      },
      "source": [
        "iface = gr.Interface(\n",
        "    fn=complete_text,\n",
        "    inputs=[\n",
        "        \"text\",\n",
        "        gr.inputs.Slider(50, 200, 1, 50),\n",
        "        gr.inputs.Slider(0.2, 2, 0.2, 1)],\n",
        "    outputs=\"text\",\n",
        "    title=\"紅樓夢生成器\",\n",
        "    description=\"起個頭, 幫你完成一段紅樓夢。可以改變 temperature, 越小生出的字越固定, 越大越隨機。\")\n",
        "iface.launch(share=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n",
            "Running on External URL: https://47961.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://47961.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f08aad3aa50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Flask 'gradio.networking'>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://47961.gradio.app')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}