{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tf2py38]",
      "language": "python",
      "name": "conda-env-tf2py38-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "「05-2. 作業說明_轉移學習的練習 (以 CNN 手寫辨識為例).ipynb」的副本",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W82Is1iwHjaI"
      },
      "source": [
        "# 主題 05-2. 轉移學習的練習\n",
        "\n",
        "【註】因 TensorFlow 2 已做了一些改變, 例如完全整合了 Keras。到 2021 年的今天, 有一些細節也做了調整。因此我們依新的規範修改了程式。最大的不同是, 以後大家直接安裝 tensorflow 即可, 不用再另外裝 keras。\n",
        "\n",
        "讓我們回顧一下生命中第一個做出來的 CNN 圖形辨識模型..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svpc5HmLHjaM"
      },
      "source": [
        "## 1. 初始準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-4_85XIHjaN"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U2kM_jOHjaP"
      },
      "source": [
        "# tf.Keras functions\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# tf.Keras dataset\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Keras utilis function\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqX_s-uRHjaQ"
      },
      "source": [
        "## 2. 讀入 MNIST 數據庫\n",
        "\n",
        "MNIST 是有一堆 0-9 的手寫數字圖庫。有 6 萬筆訓練資料, 1 萬筆測試資料。它是 \"Modified\" 版的 NIST 數據庫, 原來的版本有更多資料。這個 Modified 的版本是由 LeCun, Cortes, 及 Burges 等人做的。可以參考這個數據庫的[原始網頁](http://yann.lecun.com/exdb/mnist/)。\n",
        "\n",
        "MNIST 可以說是 Deep Learning 最有名的範例, 它被 Deep Learning 大師 Hinton 稱為「機器學習的果蠅」。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M_3LxnLHjaR"
      },
      "source": [
        "### 2.1 由 tf.Keras 讀入 MNIST\n",
        "tf.Keras 很貼心的幫我們準備好 MNIST 數據庫, 我們可以這樣讀進來 (第一周課程中已經讀過)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmjWlrtUHjaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f690e606-8479-4085-c1c8-67b06c6ef4fe"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ6Li-VXHjaT"
      },
      "source": [
        "我們可以看看資料的長相"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8PW1FiPHjaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b00197-301b-46ab-ffec-21478a11b15b"
      },
      "source": [
        "print(\"There are %d training data with size %d x %d\" %x_train.shape)\n",
        "print(\"There are %d testing  data with size %d x %d\" %x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 60000 training data with size 28 x 28\n",
            "There are 10000 testing  data with size 28 x 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znFLchwDHjaW"
      },
      "source": [
        "### 2.3 輸入格式整理\n",
        "\n",
        "我們現在要用 CNN 學手寫辨識。因為 CNN 模型的資料需要多一個 channel (通道數)，因此我們要用 `reshape` 調校一下。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaR1sr0fHjaX"
      },
      "source": [
        "x_train = x_train.reshape(60000, 28, 28, 1)/255\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-SspazHHjaX"
      },
      "source": [
        "為了後面需要，我們先將數字 0 和 1 的資料分別抓出來"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQk2uAmYHjaY"
      },
      "source": [
        "x_train_01 = x_train[y_train <= 1]\n",
        "x_test_01 = x_test[y_test <= 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djhVzcSxHjaY"
      },
      "source": [
        "並將 label 轉換成 one-hot encoding 的形式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eWE0MKNHjaZ"
      },
      "source": [
        "y_train_10 = to_categorical(y_train, 10)\n",
        "y_test_10 = to_categorical(y_test, 10)\n",
        "\n",
        "y_train_01 = y_train[y_train <= 1]\n",
        "y_train_01 = to_categorical(y_train_01, 2)\n",
        "\n",
        "y_test_01 = y_test[y_test <= 1]\n",
        "y_test_01 = to_categorical(y_test_01, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xipQZdZ1HjaZ"
      },
      "source": [
        "養成良好的習慣，適時的確認資料的大小以確保資料的一致性"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yX-YtBfHjaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a0277ab-8c33-465b-f1e7-f90fc16ce40a"
      },
      "source": [
        "x_train_01.shape, x_test_01.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12665, 28, 28, 1), (2115, 28, 28, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoPsQNJ1Hjaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "707e3ff9-366b-49ae-935e-1ce2b2373277"
      },
      "source": [
        "y_train_01.shape, y_test_01.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12665, 2), (2115, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3thhWDw8Hjab"
      },
      "source": [
        "# 3. 回顧 CNN 圖形辨識模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwzIuQbKHjab"
      },
      "source": [
        "經典的 CNN 圖形辨識模型 LeNet-5 是一個由兩層卷積層加三層全連接層所建立的神經網路，而在第二單元時，我們建立的 CNN 模型設定如下：\n",
        "\n",
        "* 起始為 <span style=\"color:red;\">3</span> 個 convolutional block\n",
        " + 每個 convolutional block 為 <span style=\"color:red;\">1</span> 個 2D Convolution + ReLU + <span style=\"color:red;\">1</span> 個 2D MaxPooling\n",
        " + 2D Convolution 的數量為 32, 64, 128\n",
        " + 每個 2D Convolution 的 `kernal_size` 為 3 或 (3, 3)，`padding` 使用 `same`\n",
        " + 每個 2D MaxPooling 的 `pool_size` 為 2 或 (2, 2)，`padding` 使用 `same`\n",
        "\n",
        "* 將輸出結果 `Flatten` 後，接著兩層全連接層，神經元個數分別為 200 和 10 (<span style=\"color:red;\">數字的類別總數)</span>\n",
        "\n",
        "我們當時建立的，是一個具有三層卷積層加兩層全連接的神經網路，其實可以看成是 LeNet-5 的一種變形。\n",
        "\n",
        "根據本單元的內容，我們可以使用下列方式使用 Sequential 重新建構第二單元的 CNN 模型。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5YuXrYjHjac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301e9428-1f1d-477e-8cd6-5682d11d82fc"
      },
      "source": [
        "# We put 3 conv. blocks together, called conv_layer.\n",
        "conv_layer = [Conv2D(32, (3, 3), padding='same', input_shape=(28,28,1)),  #第一個list\n",
        "              Activation('relu'),\n",
        "              MaxPooling2D(pool_size=(2, 2)),\n",
        "              \n",
        "              Conv2D(64, (3, 3), padding='same'),\n",
        "              Activation('relu'),\n",
        "              MaxPooling2D(pool_size=(2, 2)),\n",
        "              \n",
        "              Conv2D(128, (3, 3), padding='same'),\n",
        "              Activation('relu'),\n",
        "              MaxPooling2D(pool_size=(2, 2))]\n",
        "\n",
        "# We put Flatten, and 2 fully-connectd layers together, called fc_layer. #第二個list\n",
        "fc_layer = [Flatten(),\n",
        "            Dense(200),\n",
        "            Activation('relu'),\n",
        "            Dense(10),\n",
        "            Activation('softmax')]\n",
        "\n",
        "model = Sequential(conv_layer + fc_layer) #相加\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               230600    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2010      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 325,282\n",
            "Trainable params: 325,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT8_dkzwHjad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "21778bef-bbb1-4745-ce6e-3240eef43ac9"
      },
      "source": [
        "model.load_weights('handwriting_weights_cnn.h5', by_name = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-60017922d525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'handwriting_weights_cnn.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2317\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   2318\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2319\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2320\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n\u001b[0;32m--> 427\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'handwriting_weights_cnn.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-iqZsdmHjad"
      },
      "source": [
        "# 4. 保留前三層 convolutional layer 並進行轉移學習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvrrWE2BHjae"
      },
      "source": [
        "在此，我們一樣將 MNIST 資料集將僅有 0, 1的部分取出來，我們希望透過轉移學習建立一個類似 LeNet-5 的 0, 1 圖形辨識模型。\n",
        "\n",
        "請將下列三個 **None** 的部分進行修改，以透過轉移學習建立新的模型。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxc6PUBHHjae"
      },
      "source": [
        "new_fc_layer = [Flatten(), \n",
        "                ### Design your own fully connected structures ###\n",
        "                Dense(200)),       ##自己決定Dense(None)\n",
        "                Activation('relu'),   ##自己決定Activation\n",
        "                Dense(2),       ## Hint: how many classes in new dataset?\n",
        "                ### Remember put correct number of unit for output ###\n",
        "                Activation('softmax')]\n",
        "\n",
        "model_0_to_1 = Sequential(conv_layer + new_fc_layer)   ##= Sequential(conv_layer + None) None自己改\n",
        "model_0_to_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmTvqPBQHjae"
      },
      "source": [
        "請將下列的 **None** 進行修改，以將借過來的神經網路 **冷凍** 起來："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtsST0-OHjae"
      },
      "source": [
        "for layer in conv_layer:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eyqITFxHjaf"
      },
      "source": [
        "**冷凍**後的神經網路的 summary 會有些變化，你有發現嗎? ：)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjrR5bxcHjaf"
      },
      "source": [
        "model_0_to_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTh3NwrIHjaf"
      },
      "source": [
        "接著，我們來訓練這個(有一部分架構及權重跟別人借用的) 0, 1 手寫辨識模型吧！"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md9nLS3RHjag"
      },
      "source": [
        "model_0_to_1.compile(loss='mse', optimizer=SGD(learning_rate=0.1), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdpNsznzHjag"
      },
      "source": [
        "## 5. 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPzvUUfcHjag"
      },
      "source": [
        "model_0_to_1.fit(x_train_01, y_train_01, batch_size=100, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6HH9rDMHjag"
      },
      "source": [
        "score = model_0_to_1.evaluate(x_test_01, y_test_01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAtnt-lgHjah"
      },
      "source": [
        "print('測試資料的 loss:', score[0])\n",
        "print('測試資料正確率:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFuJ_tg9Hjah"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g28Kk6HvHjah"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4F1oOg3Hjai"
      },
      "source": [
        "## 6. 恭喜你完成了第二個透過轉移學習得到的神經網路模型！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v18OnQiHjai"
      },
      "source": [
        "不難發現，如果模型大部分的權重已經訓練好並冷凍起來，則轉移學習可以大幅減少訓練時間且訓練會更快收斂，那麼，是否還有其他重要的模型建構技巧呢？\n",
        "\n",
        "這個問題我們留待下個單元解答囉~ : )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8huYRiNHjai"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}