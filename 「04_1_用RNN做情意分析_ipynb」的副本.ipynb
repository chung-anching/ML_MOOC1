{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [conda env:tf2py38]",
      "language": "python",
      "name": "conda-env-tf2py38-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "「04-1. 用RNN做情意分析.ipynb」的副本",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkxVo6UnvocE"
      },
      "source": [
        "# 主題 04-1. 用RNN做情意分析\n",
        "\n",
        "我們終於要介紹三大神經網路的最後一個, 也就是 RNN。RNN 有不少的變型, 例如 LSTM 和 GRU 等等, 不過我們都通稱叫 RNN。RNN 是一種「有記憶」的神經網路, 非常適合時間序列啦, 或是不定長度的輸入資料。\n",
        "\n",
        "我們來看看怎麼樣用 RNN 做電影評論的「情意分析」, 也就是知道一則評論究竟是「正評」還是「負評」。\n",
        "\n",
        "【註】因 TensorFlow 2 已做了一些改變, 例如完全整合了 Keras。到 2021 年的今天, 有一些細節也做了調整。因此我們依新的規範修改了程式。最大的不同是, 以後大家直接安裝 tensorflow 即可, 不用再另外裝 keras。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMCE-8iovocJ"
      },
      "source": [
        "## 1. 初始準備\n",
        "\n",
        "基本上和之前是一樣的, 我們就不再說明。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lehnJJavocK"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nJ53A4dvocL"
      },
      "source": [
        "## 2. 讀入 IMDB 電影數據庫\n",
        "\n",
        "今天我們要評入 IMDB 電影數據庫影評的部份。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrj4GFaSvocM"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se-nTfcFvocQ"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-jZnNWRvocR",
        "outputId": "68d19de6-cb17-4a34-e8f0-592126086e8d"
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0tWJ_RGvocT",
        "outputId": "6cd935f3-824f-43cc-c415-9bb569b4b48b"
      },
      "source": [
        "len(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH5a1gHgvocU"
      },
      "source": [
        "### 2.1 輸入資料部份\n",
        "\n",
        "我們來看一下輸入部份長什麼樣子?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXa0qf9GvocV",
        "outputId": "e3c39aac-b47b-4065-f0ce-ab30ccdd73fb"
      },
      "source": [
        "for i in range(10):\n",
        "    print(len(x_train[i]), end=', ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "218, 189, 141, 550, 147, 43, 123, 562, 233, 130, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfkXGF7evocW"
      },
      "source": [
        "### 2.2 輸出資料部份\n",
        "\n",
        "輸出方面應該很容易想像, 我們來看看前 10 筆。結果自然就是 0 (負評) 或 1 (正評)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc4omqbevocX",
        "outputId": "4a529d95-ab4c-49f8-bbb1-56fa6e1e4a6c"
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6EY5oMpvocY"
      },
      "source": [
        "### 2.3 送入神經網路的輸入處理\n",
        "\n",
        "雖然 RNN 是可以處理不同長度的輸入, 在寫程式時我們還是要\n",
        "\n",
        "* 設輸入文字長度的上限\n",
        "* 把每段文字都弄成一樣長, 太短的後面補上 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNCwyWTDvocY"
      },
      "source": [
        "from tensorflow.keras.preprocessing import sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhfKg1xmvocZ"
      },
      "source": [
        "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-LBB7RBvocZ",
        "outputId": "394c1ea6-6ee0-45bf-9b90-37bca1c8b25e"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP_fkckBvoca"
      },
      "source": [
        "至此我們可以來寫我們的第一個 RNN 了!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDrPeO_svoca"
      },
      "source": [
        "## 3. 打造你的 RNN\n",
        "\n",
        "這裡我們選用 LSTM, 基本上用哪種 RNN 寫法都是差不多的!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yztJcHdmvoca"
      },
      "source": [
        "### 3.1 決定神經網路架構\n",
        "\n",
        "* 先將 10000 維的文字壓到 128 維 (one hot encoding)\n",
        "* 然後用 128 個 LSTM (不一定要跟前面的128數字一樣)\n",
        "* 最後一個 output, 直接用 sigmoid 送出 (用sigmoid因為最符合輸出是0-1的需求)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1SbbW5Gvocb"
      },
      "source": [
        "### 3.2 建構我們的神經網路\n",
        "\n",
        "文字我們用 1-hot 表示是很標準的方式, 不過要注意的是, 因為我們指定要 1 萬個字, 所以每個字是用 1 萬維的向量表示! 這一來很浪費記憶空間, 二來字和字間基本上是沒有關係的。我們可以用某種「合理」的方式, 把字壓到比較小的維度, 這些向量又代表某些意思 (比如說兩個字代表的向量角度小表相關程度大) 等等。\n",
        "\n",
        "這聽來很複雜的事叫 \"word embedding\", 而事實上 Keras 會幫我們做。我們只需告訴 Keras 原來最大的數字是多少 (10000), 還有我們打算壓到幾維 (128)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTlpeAN-vocb"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB-3LXuzvocc"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLKcewpevocc"
      },
      "source": [
        "model.add(Embedding(10000, 128)) #把一個字從10000維壓到128維"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI2S11dZvocc"
      },
      "source": [
        "model.add(LSTM(150))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37StRshfvocd"
      },
      "source": [
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5k7DwYvvocd"
      },
      "source": [
        "### 3.3 組裝\n",
        "\n",
        "這次我們用 binary_crossentropy 做我們的 loss function, 另外用一個很潮的 Adam 學習法。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAJgpdegvocd",
        "outputId": "2e0a19f1-7d1a-425b-9f5f-6b7df504fb21"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 150)               167400    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 1,447,551\n",
            "Trainable params: 1,447,551\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P76EXUqKvoce",
        "outputId": "6dbbcaf2-4346-4d9f-e606-f6acfe8d951a"
      },
      "source": [
        "3*(128+150+1)*150  #每個LSTM有三個gates(小小的神經元) 3*(128上層+150這層+1 bias)*150 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125550"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYDF8Jppvoce",
        "outputId": "4c79ad8d-7b53-4395-ab58-7dbd64b38c4b"
      },
      "source": [
        "(128+150+1)*150 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41850"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRY0mLnDvoce",
        "outputId": "57c62cb8-222c-413f-a880-b5abb8bb955a"
      },
      "source": [
        "125550 + 41850"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "167400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGD7-dZSvocf"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ark8mWZovocg"
      },
      "source": [
        "## 4. 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooyGVk1nvocg",
        "outputId": "10d716ef-715d-40b5-a58c-1cce89272e8f"
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "         batch_size=32,\n",
        "         epochs=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "782/782 [==============================] - 10s 11ms/step - loss: 0.5123 - accuracy: 0.7313\n",
            "Epoch 2/15\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.2607 - accuracy: 0.8948\n",
            "Epoch 3/15\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.1821 - accuracy: 0.9326\n",
            "Epoch 4/15\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.1138 - accuracy: 0.9597\n",
            "Epoch 5/15\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.0812 - accuracy: 0.9734\n",
            "Epoch 6/15\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.0611 - accuracy: 0.9797\n",
            "Epoch 7/15\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.0385 - accuracy: 0.9887\n",
            "Epoch 8/15\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.0260 - accuracy: 0.9918\n",
            "Epoch 9/15\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.0260 - accuracy: 0.9914\n",
            "Epoch 10/15\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.0190 - accuracy: 0.9939\n",
            "Epoch 11/15\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.0263 - accuracy: 0.9921\n",
            "Epoch 12/15\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.0099 - accuracy: 0.9973\n",
            "Epoch 13/15\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.0135 - accuracy: 0.9965\n",
            "Epoch 14/15\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.0097 - accuracy: 0.9970\n",
            "Epoch 15/15\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.0124 - accuracy: 0.9967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe9eb7591c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3baEtA4Hvoch"
      },
      "source": [
        "## 5. 檢視結果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mastPV_voch"
      },
      "source": [
        "### 5.1 分數\n",
        "\n",
        "我們照例來看看測試資料的分數。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38HjZftkvoci",
        "outputId": "71bfc168-46dc-4e1f-e07d-663a3a2b3e16"
      },
      "source": [
        "score = model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 3s 3ms/step - loss: 0.9819 - accuracy: 0.8173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gz-2dHPvoci",
        "outputId": "0f163baf-eb8a-4789-d56c-e529181a8511"
      },
      "source": [
        "print('測試資料的 loss', score[0])\n",
        "print('測試資料的正確率', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "測試資料的 loss 0.9819172620773315\n",
            "測試資料的正確率 0.8172799944877625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAR5FLJNvoci"
      },
      "source": [
        "### 5.2 儲存結果\n",
        "\n",
        "這裡有 8 成我們可以正確分辨, 看來還不差, 照例我們把結果存檔。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjGlQ70Bvocj",
        "outputId": "4c7872af-c8ce-4dbc-bebb-53e979980828"
      },
      "source": [
        "model_json = model.to_json()\n",
        "open('imdb_model_architecture.json', 'w').write(model_json)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOb9TAZvvocj"
      },
      "source": [
        "model.save_weights('imdb_model_weights.h5') #把weight存起來"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2nv0nnMvocj"
      },
      "source": [
        "### 另一種存的方式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTRsLqNEvocj"
      },
      "source": [
        "model.save('myrnn.h5') #把weight跟架構全部都存起來了，下一次用load就可以取出來"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}